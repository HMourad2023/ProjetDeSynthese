{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Table des matières\n",
    "\n",
    "1. [Importation des Bibliothèques](#importation-des-bibliothèques)\n",
    "2. [Chargement des Données](#chargement-des-données)\n",
    "3. [Préparation des Données](#préparation-des-données)\n",
    "4. [Transformation des Données](#transformation-des-données)\n",
    "5. [Division des Données](#division-des-données)\n",
    "6. [Sélection des Caractéristiques](#sélection-des-caractéristiques)\n",
    "7. [Filtrage des Caractéristiques](#filtrage-des-caractéristiques)\n",
    "8. [Entraînement et Enregistrement des Modèles](#entra%C3%AEnement-et-enregistrement-des-mod%C3%A8les)\n",
    "9. [Validation du Modèle](#validation-du-mod%C3%A8le)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Importation des Bibliothèques\n",
    "\n",
    "Nous commençons par importer toutes les bibliothèques nécessaires pour le traitement des données, la modélisation et l'enregistrement des résultats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-07 11:42:13.263803\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "\n",
    "print(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from joblib import parallel_backend\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.models import validate_serving_input, convert_input_example_to_serving_input\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des Données\n",
    "Définissons une fonction pour charger les données depuis le fichier CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PASSENGERS</th>\n",
       "      <th>FREIGHT</th>\n",
       "      <th>MAIL</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>UNIQUE_CARRIER</th>\n",
       "      <th>AIRLINE_ID</th>\n",
       "      <th>UNIQUE_CARRIER_NAME</th>\n",
       "      <th>REGION</th>\n",
       "      <th>CARRIER</th>\n",
       "      <th>CARRIER_NAME</th>\n",
       "      <th>...</th>\n",
       "      <th>DEST</th>\n",
       "      <th>DEST_CITY_NAME</th>\n",
       "      <th>DEST_COUNTRY</th>\n",
       "      <th>DEST_COUNTRY_NAME</th>\n",
       "      <th>DEST_WAC</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>QUARTER</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DISTANCE_GROUP</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>AMQ</td>\n",
       "      <td>20201</td>\n",
       "      <td>Ameristar Air Cargo</td>\n",
       "      <td>I</td>\n",
       "      <td>AMQ</td>\n",
       "      <td>Ameristar Air Cargo</td>\n",
       "      <td>...</td>\n",
       "      <td>YQG</td>\n",
       "      <td>Windsor, Canada</td>\n",
       "      <td>CA</td>\n",
       "      <td>Canada</td>\n",
       "      <td>936</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>AMQ</td>\n",
       "      <td>20201</td>\n",
       "      <td>Ameristar Air Cargo</td>\n",
       "      <td>I</td>\n",
       "      <td>AMQ</td>\n",
       "      <td>Ameristar Air Cargo</td>\n",
       "      <td>...</td>\n",
       "      <td>YIP</td>\n",
       "      <td>Detroit, MI</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>43</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>AMQ</td>\n",
       "      <td>20201</td>\n",
       "      <td>Ameristar Air Cargo</td>\n",
       "      <td>I</td>\n",
       "      <td>AMQ</td>\n",
       "      <td>Ameristar Air Cargo</td>\n",
       "      <td>...</td>\n",
       "      <td>YIP</td>\n",
       "      <td>Detroit, MI</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>43</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>AMQ</td>\n",
       "      <td>20201</td>\n",
       "      <td>Ameristar Air Cargo</td>\n",
       "      <td>I</td>\n",
       "      <td>AMQ</td>\n",
       "      <td>Ameristar Air Cargo</td>\n",
       "      <td>...</td>\n",
       "      <td>YIP</td>\n",
       "      <td>Detroit, MI</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>43</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>AMQ</td>\n",
       "      <td>20201</td>\n",
       "      <td>Ameristar Air Cargo</td>\n",
       "      <td>I</td>\n",
       "      <td>AMQ</td>\n",
       "      <td>Ameristar Air Cargo</td>\n",
       "      <td>...</td>\n",
       "      <td>YIP</td>\n",
       "      <td>Detroit, MI</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>43</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PASSENGERS  FREIGHT  MAIL  DISTANCE UNIQUE_CARRIER  AIRLINE_ID  \\\n",
       "0         0.0      0.0   0.0      29.0            AMQ       20201   \n",
       "1         0.0      0.0   0.0      29.0            AMQ       20201   \n",
       "2         0.0      0.0   0.0      29.0            AMQ       20201   \n",
       "3         0.0      0.0   0.0      29.0            AMQ       20201   \n",
       "4         0.0      0.0   0.0      29.0            AMQ       20201   \n",
       "\n",
       "   UNIQUE_CARRIER_NAME REGION CARRIER         CARRIER_NAME  ...  DEST  \\\n",
       "0  Ameristar Air Cargo      I     AMQ  Ameristar Air Cargo  ...   YQG   \n",
       "1  Ameristar Air Cargo      I     AMQ  Ameristar Air Cargo  ...   YIP   \n",
       "2  Ameristar Air Cargo      I     AMQ  Ameristar Air Cargo  ...   YIP   \n",
       "3  Ameristar Air Cargo      I     AMQ  Ameristar Air Cargo  ...   YIP   \n",
       "4  Ameristar Air Cargo      I     AMQ  Ameristar Air Cargo  ...   YIP   \n",
       "\n",
       "    DEST_CITY_NAME  DEST_COUNTRY  DEST_COUNTRY_NAME  DEST_WAC  YEAR QUARTER  \\\n",
       "0  Windsor, Canada            CA             Canada       936  2010       2   \n",
       "1      Detroit, MI            US      United States        43  2010       1   \n",
       "2      Detroit, MI            US      United States        43  2010       2   \n",
       "3      Detroit, MI            US      United States        43  2010       3   \n",
       "4      Detroit, MI            US      United States        43  2010       3   \n",
       "\n",
       "  MONTH DISTANCE_GROUP  CLASS  \n",
       "0     6              1      P  \n",
       "1     3              1      P  \n",
       "2     6              1      P  \n",
       "3     8              1      P  \n",
       "4     9              1      P  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"C:/Users/Asus_M/Desktop/data.csv\"\n",
    "\n",
    "def load_data(data_path):\n",
    "    data = pd.read_csv(data_path, index_col=0)\n",
    "    return data\n",
    "\n",
    "data = load_data(data_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des Données\n",
    "Préparons les données en nettoyant et en ajustant les types de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54942, 26)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_data(data):\n",
    "    data.columns = data.columns.str.replace(' ', '', regex=False)\n",
    "    colonnes_avec_ID = [col for col in data.columns if 'ID' in col]\n",
    "    data.drop(columns=colonnes_avec_ID, axis=1, inplace=True)\n",
    "    \n",
    "    # Conversion des colonnes catégorielles en objets\n",
    "    cat_columns = ['CARRIER_GROUP', 'CARRIER_GROUP_NEW', 'ORIGIN_WAC', 'DEST_WAC', 'YEAR', 'QUARTER', 'MONTH', 'DISTANCE_GROUP']\n",
    "    data[cat_columns] = data[cat_columns].astype(object)\n",
    "    \n",
    "    # Suppression des lignes avec PASSENGERS, FREIGHT, et MAIL tous égaux à 0\n",
    "    lignes_zero_valeurs = data[(data['PASSENGERS'] == 0) & (data['FREIGHT'] == 0) & (data['MAIL'] == 0)].index\n",
    "    data.drop(lignes_zero_valeurs, inplace=True)\n",
    "    \n",
    "    # Suppression des valeurs manquantes\n",
    "    data.dropna(inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "prepared_data = prepare_data(data)\n",
    "prepared_data.head()\n",
    "prepared_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation des Données\n",
    "Transformons les données en encodant les variables catégorielles et en appliquant une transformation logarithmique aux données numériques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Log_PASSENGERS', 'Log_FREIGHT', 'Log_MAIL', 'Log_DISTANCE',\n",
       "       'UNIQUE_CARRIER', 'UNIQUE_CARRIER_NAME', 'REGION', 'CARRIER',\n",
       "       'CARRIER_NAME', 'CARRIER_GROUP', 'CARRIER_GROUP_NEW', 'ORIGIN',\n",
       "       'ORIGIN_CITY_NAME', 'ORIGIN_COUNTRY', 'ORIGIN_COUNTRY_NAME',\n",
       "       'ORIGIN_WAC', 'DEST', 'DEST_CITY_NAME', 'DEST_COUNTRY',\n",
       "       'DEST_COUNTRY_NAME', 'DEST_WAC', 'YEAR', 'QUARTER', 'MONTH',\n",
       "       'DISTANCE_GROUP', 'CLASS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_data(prepared_data):\n",
    "    label_encoder = LabelEncoder()\n",
    "    cat_data = prepared_data.select_dtypes(include='object')\n",
    "    num_data = prepared_data.select_dtypes(exclude='object')\n",
    "    \n",
    "    # Transformation logarithmique\n",
    "    num_data['Log_PASSENGERS'] = np.log1p(num_data['PASSENGERS'])\n",
    "    num_data['Log_FREIGHT'] = np.log1p(num_data['FREIGHT'])\n",
    "    num_data['Log_MAIL'] = np.log1p(num_data['MAIL'])\n",
    "    num_data['Log_DISTANCE'] = np.log1p(num_data['DISTANCE'])\n",
    "    num_data.drop(columns=['PASSENGERS', 'FREIGHT', 'MAIL', 'DISTANCE'], inplace=True)\n",
    "    \n",
    "    # Encodage des variables catégorielles\n",
    "    for column in cat_data.columns:\n",
    "        cat_data[column] = label_encoder.fit_transform(cat_data[column])\n",
    "    \n",
    "    data = pd.concat([num_data, cat_data], axis=1)\n",
    "    return data\n",
    "\n",
    "transformed_data = transform_data(prepared_data)\n",
    "transformed_data.head()\n",
    "transformed_data.shape\n",
    "transformed_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Division des Données\n",
    "Divisons les données en ensembles d'entraînement et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43953, 23)\n",
      "(43953, 3)\n",
      "(10989, 23)\n",
      "(10989, 3)\n"
     ]
    }
   ],
   "source": [
    "def split_data(transformed_data):\n",
    "    X = transformed_data.drop(columns=[\"Log_PASSENGERS\", \"Log_FREIGHT\", \"Log_MAIL\"])\n",
    "    y = transformed_data[[\"Log_PASSENGERS\", \"Log_FREIGHT\", \"Log_MAIL\"]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(transformed_data)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sélection des Caractéristiques\n",
    "Utilisons la méthode SequentialFeatureSelector pour sélectionner les meilleures caractéristiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  23 | elapsed:  2.7min remaining:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  23 | elapsed:  4.1min finished\n",
      "\n",
      "[2024-08-07 11:46:37] Features: 22/1 -- score: -0.749452776786056[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  22 | elapsed:  1.8min remaining:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  22 | elapsed:  3.2min finished\n",
      "\n",
      "[2024-08-07 11:49:49] Features: 21/1 -- score: -0.7465249047195583[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  21 | elapsed:  1.8min remaining:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:  3.0min finished\n",
      "\n",
      "[2024-08-07 11:52:47] Features: 20/1 -- score: -0.7443903165484197[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  20 | elapsed:  1.7min remaining:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  2.7min finished\n",
      "\n",
      "[2024-08-07 11:55:28] Features: 19/1 -- score: -0.742873737953648[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  19 | elapsed:  1.6min remaining:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  19 | elapsed:  2.4min remaining:   27.2s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:  2.4min finished\n",
      "\n",
      "[2024-08-07 11:57:55] Features: 18/1 -- score: -0.7423498984093619[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  18 | elapsed:  1.4min remaining:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  18 | elapsed:  2.1min remaining:   25.5s\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:  2.2min finished\n",
      "\n",
      "[2024-08-07 12:00:04] Features: 17/1 -- score: -0.7425118246052463[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  17 | elapsed:  1.3min remaining:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  17 | elapsed:  1.5min remaining:   37.3s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:  1.9min finished\n",
      "\n",
      "[2024-08-07 12:02:01] Features: 16/1 -- score: -0.7410849813637478[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  16 | elapsed:  1.2min remaining:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  16 | elapsed:  1.4min remaining:   39.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:  1.8min finished\n",
      "\n",
      "[2024-08-07 12:03:47] Features: 15/1 -- score: -0.742824729939807[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:  1.3min remaining:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.6min finished\n",
      "\n",
      "[2024-08-07 12:05:21] Features: 14/1 -- score: -0.7415322347980119[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  14 | elapsed:  1.2min remaining:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:  1.4min finished\n",
      "\n",
      "[2024-08-07 12:06:46] Features: 13/1 -- score: -0.7399686105927322[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  13 | elapsed:  1.2min remaining:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  13 | elapsed:  1.2min remaining:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:  1.3min finished\n",
      "\n",
      "[2024-08-07 12:08:04] Features: 12/1 -- score: -0.7410291688958598[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  12 | elapsed:  1.1min remaining:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  12 | elapsed:  1.1min remaining:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  1.1min finished\n",
      "\n",
      "[2024-08-07 12:09:09] Features: 11/1 -- score: -0.7433936826897308[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  11 | elapsed:   56.2s remaining:   46.8s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:   58.1s finished\n",
      "\n",
      "[2024-08-07 12:10:07] Features: 10/1 -- score: -0.7434790362091358[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:   49.6s remaining:   49.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   50.8s finished\n",
      "\n",
      "[2024-08-07 12:10:58] Features: 9/1 -- score: -0.7498389223943712[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:   44.2s remaining:   22.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   44.5s finished\n",
      "\n",
      "[2024-08-07 12:11:43] Features: 8/1 -- score: -0.7537882071291818[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   8 | elapsed:   33.5s remaining:   20.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   34.7s finished\n",
      "\n",
      "[2024-08-07 12:12:18] Features: 7/1 -- score: -0.7617312812372604[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   7 | elapsed:   26.4s remaining:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:   27.0s finished\n",
      "\n",
      "[2024-08-07 12:12:45] Features: 6/1 -- score: -0.7994019659744437[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:   18.0s remaining:   18.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:   19.4s finished\n",
      "\n",
      "[2024-08-07 12:13:04] Features: 5/1 -- score: -0.8325361968516242[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    8.8s remaining:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    9.4s finished\n",
      "\n",
      "[2024-08-07 12:13:14] Features: 4/1 -- score: -0.953025831823577[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:    6.2s remaining:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    6.6s finished\n",
      "\n",
      "[2024-08-07 12:13:21] Features: 3/1 -- score: -1.2123174721235088[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    3.2s finished\n",
      "\n",
      "[2024-08-07 12:13:24] Features: 2/1 -- score: -1.677078070230581[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices des caractéristiques sélectionnées : [0, 3, 5, 7, 8, 9, 12, 13, 14, 18, 20, 21, 22]\n",
      "Noms des caractéristiques sélectionnées : ['Log_DISTANCE', 'REGION', 'CARRIER_NAME', 'CARRIER_GROUP_NEW', 'ORIGIN', 'ORIGIN_CITY_NAME', 'ORIGIN_WAC', 'DEST', 'DEST_CITY_NAME', 'YEAR', 'MONTH', 'DISTANCE_GROUP', 'CLASS']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    1.3s finished\n",
      "\n",
      "[2024-08-07 12:13:25] Features: 1/1 -- score: -3.8728223161012885"
     ]
    }
   ],
   "source": [
    "def select_features(X_train, y_train, k_features='best', n_jobs=-1, cv=3, scoring='neg_mean_squared_error', verbose=2):\n",
    "    etr = ExtraTreesRegressor(n_jobs=n_jobs,random_state=42)\n",
    "    sfs = SFS(\n",
    "        etr,\n",
    "        k_features=k_features,\n",
    "        forward=False,\n",
    "        floating=False,\n",
    "        verbose=verbose,\n",
    "        scoring=scoring,\n",
    "        cv=cv,\n",
    "        n_jobs=n_jobs\n",
    "    )\n",
    "    \n",
    "    # Perform feature selection using joblib for parallel processing\n",
    "    with parallel_backend('threading', n_jobs=n_jobs):\n",
    "        sfs = sfs.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the selected feature indices\n",
    "    selected_feature_indices = sfs.k_feature_idx_\n",
    "    \n",
    "    if isinstance(X_train, pd.DataFrame):\n",
    "        feature_names = X_train.columns[list(selected_feature_indices)]\n",
    "        return list(selected_feature_indices), feature_names.tolist()\n",
    "    else:\n",
    "        return list(selected_feature_indices)\n",
    "\n",
    "selected_indices, selected_feature_names = select_features(X_train, y_train)\n",
    "print(\"Indices des caractéristiques sélectionnées :\", selected_indices)\n",
    "print(\"Noms des caractéristiques sélectionnées :\", selected_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrage des Caractéristiques\n",
    "Filtrons les données d'entraînement et de test pour ne conserver que les caractéristiques sélectionnées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train avec les caractéristiques sélectionnées : (43953, 13)\n",
      "X_test avec les caractéristiques sélectionnées : (10989, 13)\n",
      "y_train : (43953, 3)\n",
      "y_test : (10989, 3)\n"
     ]
    }
   ],
   "source": [
    "def filter_features(X_train, X_test, selected_indices):\n",
    "    if isinstance(X_train, pd.DataFrame):\n",
    "        return X_train.iloc[:, selected_indices], X_test.iloc[:, selected_indices]\n",
    "    else:\n",
    "        return X_train[:, selected_indices], X_test[:, selected_indices]\n",
    "\n",
    "X_train_selected, X_test_selected = filter_features(X_train, X_test, selected_indices)\n",
    "print(\"X_train avec les caractéristiques sélectionnées :\", X_train_selected.shape)\n",
    "print(\"X_test avec les caractéristiques sélectionnées :\", X_test_selected.shape)\n",
    "print(\"y_train :\", y_train.shape)\n",
    "print(\"y_test :\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enregistrement des features dans un fichier TXT :\n",
    "Aprés l'etape de selection ,nous enregistrons les données avec les features selectionnées dans un fichier txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les noms des colonnes ont été enregistrés dans features.txt.\n"
     ]
    }
   ],
   "source": [
    "columns = X_train_selected.columns.tolist()\n",
    "\n",
    "with open('features.txt', 'w') as file:\n",
    "    for column in columns:\n",
    "        file.write(f\"{column}\\n\")\n",
    "\n",
    "print(\"Les noms des colonnes ont été enregistrés dans features.txt.\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement et Enregistrement des Modèles\n",
    "Entraînons plusieurs modèles et enregistrons-les avec MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/07 12:13:28 INFO mlflow.tracking.fluent: Experiment with name 'experience1' does not exist. Creating a new experiment.\n",
      "2024/08/07 12:13:36 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2024/08/07 12:13:36 INFO mlflow.tracking._tracking_service.client: 🏃 View run LinearRegression at: http://localhost:5000/#/experiments/995444263188306398/runs/9b436f8930a743d3adfc4541593898b3.\n",
      "2024/08/07 12:13:36 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/995444263188306398.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle: LinearRegression, R2: 0.1832, RMSE: 2.9935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/07 12:14:06 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2024/08/07 12:14:07 INFO mlflow.tracking._tracking_service.client: 🏃 View run RandomForestRegressor at: http://localhost:5000/#/experiments/995444263188306398/runs/2ebdf0293b6e4e99a0ab0d715ffbf9b5.\n",
      "2024/08/07 12:14:07 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/995444263188306398.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle: RandomForestRegressor, R2: 0.9263, RMSE: 0.8188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/07 12:14:11 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2024/08/07 12:14:11 INFO mlflow.tracking._tracking_service.client: 🏃 View run KNeighborsRegressor at: http://localhost:5000/#/experiments/995444263188306398/runs/ec5dac052297454b8e9e599f66e7e199.\n",
      "2024/08/07 12:14:11 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/995444263188306398.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle: KNeighborsRegressor, R2: 0.8440, RMSE: 1.2745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/07 12:14:35 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2024/08/07 12:14:35 INFO mlflow.tracking._tracking_service.client: 🏃 View run ExtraTreesRegressor at: http://localhost:5000/#/experiments/995444263188306398/runs/7804aba9c89a4213ba39fa23753ea05f.\n",
      "2024/08/07 12:14:35 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/995444263188306398.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle: ExtraTreesRegressor, R2: 0.9262, RMSE: 0.8243\n",
      "\n",
      "Le meilleur modèle est 'RandomForestRegressor' avec R2 = 0.9263 et RMSE = 0.8188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/07 12:14:44 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "Successfully registered model 'Best_Model'.\n",
      "2024/08/07 12:14:44 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Best_Model, version 1\n",
      "Created version '1' of model 'Best_Model'.\n",
      "2024/08/07 12:14:44 INFO mlflow.tracking._tracking_service.client: 🏃 View run Best_Model_Production at: http://localhost:5000/#/experiments/995444263188306398/runs/c54223f5e2cd4eeaafa34bdd9b77f31a.\n",
      "2024/08/07 12:14:44 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/995444263188306398.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le modèle 'RandomForestRegressor' a été enregistré et mis en production.\n"
     ]
    }
   ],
   "source": [
    "# Définir l'URI de suivi et l'expérience MLflow\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment('experience1')\n",
    "\n",
    "def train_and_log_model(model_name, model, X_train_selected, y_train, X_test_selected, y_test):\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Entraîner le modèle\n",
    "        model.fit(X_train_selected, y_train)\n",
    "        \n",
    "        # Prédictions\n",
    "        predictions = model.predict(X_test_selected)\n",
    "        \n",
    "        # Calculer l'erreur quadratique moyenne et R2\n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        rmse = np.sqrt(mse)  # Calculer RMSE\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "        \n",
    "        # Loguer les paramètres et les résultats\n",
    "        mlflow.log_params(model.get_params())\n",
    "        mlflow.log_metric(\"mean_squared_error\", mse)\n",
    "        mlflow.log_metric(\"root_mean_squared_error\", rmse)\n",
    "        mlflow.log_metric(\"R2\", r2)\n",
    "        \n",
    "        # Loguer le modèle\n",
    "        mlflow.sklearn.log_model(model, model_name)\n",
    "        \n",
    "        return r2, rmse\n",
    "\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'RandomForestRegressor': RandomForestRegressor(),\n",
    "    'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "    'ExtraTreesRegressor': ExtraTreesRegressor()\n",
    "}\n",
    "\n",
    "best_model_name = None\n",
    "best_r2 = -np.inf\n",
    "best_rmse = np.inf\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    r2, rmse = train_and_log_model(model_name, model, X_train_selected, y_train, X_test_selected, y_test)\n",
    "    print(f\"Modèle: {model_name}, R2: {r2:.4f}, RMSE: {rmse:.4f}\")\n",
    "    \n",
    "    # Mettre à jour le meilleur modèle basé sur R2 et RMSE\n",
    "    if r2 > best_r2 and rmse < best_rmse:\n",
    "        best_r2 = r2\n",
    "        best_rmse = rmse\n",
    "        best_model_name = model_name\n",
    "\n",
    "if best_model_name:\n",
    "    print(f\"\\nLe meilleur modèle est '{best_model_name}' avec R2 = {best_r2:.4f} et RMSE = {best_rmse:.4f}\")\n",
    "\n",
    "    # Enregistrer le meilleur modèle\n",
    "    with mlflow.start_run(run_name=\"Best_Model_Production\") as best_run:\n",
    "        best_model = models[best_model_name]\n",
    "        mlflow.sklearn.log_model(best_model, \"best_model\")\n",
    "        mlflow.log_metric(\"R2\", best_r2)\n",
    "        mlflow.log_metric(\"root_mean_squared_error\", best_rmse)\n",
    "        \n",
    "        # Enregistrer le modèle dans le registre MLflow\n",
    "        model_uri = f\"runs:/{best_run.info.run_id}/best_model\"\n",
    "        mlflow.register_model(model_uri, \"Best_Model\")\n",
    "\n",
    "        # Déplacer le modèle vers le stage de production\n",
    "        client = MlflowClient()\n",
    "        latest_version = client.get_latest_versions(\"Best_Model\", stages=[\"None\"])[0].version\n",
    "        client.transition_model_version_stage(\n",
    "            name=\"Best_Model\",\n",
    "            version=latest_version,\n",
    "            stage=\"Production\"\n",
    "        )\n",
    "\n",
    "    print(f\"Le modèle '{best_model_name}' a été enregistré et mis en production.\")\n",
    "else:\n",
    "    print(\"Aucun modèle n'a été sélectionné.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation du Modèle\n",
    "Vérifions que le modèle enregistré fonctionne correctement avant de le déployer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model URI in production: models:/Best_Model/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 5/5 [00:46<00:00,  9.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le nombre de passagers prévu est : 50\n",
      "La quantité de Fret prévue : 1\n",
      "La quantité de Courrier prévue est : 1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Define MLflow tracking URI\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "def get_model_uri_from_stage(model_name, stage=\"Production\"):\n",
    "    client = MlflowClient()\n",
    "    # Get the latest version of the model in the specified stage\n",
    "    model_versions = client.get_latest_versions(model_name, stages=[stage])\n",
    "    if not model_versions:\n",
    "        raise ValueError(f\"No version of model '{model_name}' found in stage '{stage}'.\")\n",
    "    \n",
    "    # Get the model URI\n",
    "    latest_version = model_versions[0].version\n",
    "    model_uri = f\"models:/{model_name}/{latest_version}\"\n",
    "    return model_uri\n",
    "\n",
    "def convert_input_example_to_serving_input(input_example):\n",
    "    # Convert DataFrame to NumPy array\n",
    "    if isinstance(input_example, pd.DataFrame):\n",
    "        input_example = input_example.values\n",
    "    \n",
    "    # Return as a list of lists (2D array) which is often expected by models\n",
    "    return input_example.tolist()\n",
    "\n",
    "def validate_serving_input(model_uri, serving_payload):\n",
    "    # Load the model\n",
    "    model = mlflow.pyfunc.load_model(model_uri)\n",
    "    \n",
    "    # Make a prediction\n",
    "    prediction = model.predict(serving_payload)\n",
    "    \n",
    "    # Print the prediction\n",
    "    prediction_original = np.exp(prediction)\n",
    "    passengers = prediction_original[0][0]\n",
    "    freight = prediction_original[0][1]\n",
    "    mail = prediction_original[0][2]\n",
    "\n",
    "    print(f\"Le nombre de passagers prévu est : {math.floor(passengers)}\")\n",
    "    print(f\"La quantité de Fret prévue : {math.floor(freight)}\")\n",
    "    print(f\"La quantité de Courrier prévue est : {math.floor(mail)}\")\n",
    "\n",
    "\n",
    "# Example input data\n",
    "INPUT_EXAMPLE = {\n",
    "    \"Log_DISTANCE\": 7.723120,\n",
    "    \"REGION\": 1,\n",
    "    \"CARRIER_NAME\": 7,\n",
    "    \"CARRIER_GROUP_NEW\": 2,\n",
    "    \"ORIGIN\": 326,\n",
    "    \"ORIGIN_WAC\": 48,\n",
    "    \"DEST\": 412,\n",
    "    \"DEST_CITY_NAME\": 351,\n",
    "    \"DEST_WAC\": 58,\n",
    "    \"YEAR\": 2,\n",
    "    \"MONTH\": 6,\n",
    "    \"DISTANCE_GROUP\": 4,\n",
    "    \"CLASS\": 0\n",
    "}\n",
    "\n",
    "\n",
    "# Convert input example to DataFrame\n",
    "input_df = pd.DataFrame([INPUT_EXAMPLE])\n",
    "\n",
    "# Obtain the model URI\n",
    "model_name = \"Best_Model\"  # Model name\n",
    "model_uri = get_model_uri_from_stage(model_name, stage=\"Production\")\n",
    "print(f\"Model URI in production: {model_uri}\")\n",
    "\n",
    "# Convert the input example to a serving input format\n",
    "serving_payload = convert_input_example_to_serving_input(input_df)\n",
    "\n",
    "# Validate the model with the example input\n",
    "validate_serving_input(model_uri, serving_payload)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-07 12:15:32.396282\n"
     ]
    }
   ],
   "source": [
    "end_time = datetime.datetime.now()\n",
    "\n",
    "print(end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 day, 23:26:40.867521\n"
     ]
    }
   ],
   "source": [
    "temps_total_pour_execution = start_time - end_time\n",
    "\n",
    "print(temps_total_pour_execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
