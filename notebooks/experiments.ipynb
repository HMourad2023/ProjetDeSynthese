{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Table des mati√®res\n",
    "\n",
    "1. [Importation des Biblioth√®ques](#importation-des-biblioth√®ques)\n",
    "2. [Chargement des Donn√©es](#chargement-des-donn√©es)\n",
    "3. [Pr√©paration des Donn√©es](#pr√©paration-des-donn√©es)\n",
    "4. [Transformation des Donn√©es](#transformation-des-donn√©es)\n",
    "5. [Division des Donn√©es](#division-des-donn√©es)\n",
    "6. [S√©lection des Caract√©ristiques](#s√©lection-des-caract√©ristiques)\n",
    "7. [Filtrage des Caract√©ristiques](#filtrage-des-caract√©ristiques)\n",
    "8. [Entra√Ænement et Enregistrement des Mod√®les](#entra%C3%AEnement-et-enregistrement-des-mod%C3%A8les)\n",
    "9. [Validation du Mod√®le](#validation-du-mod%C3%A8le)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Importation des Biblioth√®ques\n",
    "\n",
    "Nous commen√ßons par importer toutes les biblioth√®ques n√©cessaires pour le traitement des donn√©es, la mod√©lisation et l'enregistrement des r√©sultats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-07 11:42:13.263803\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "\n",
    "print(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from joblib import parallel_backend\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.models import validate_serving_input, convert_input_example_to_serving_input\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des Donn√©es\n",
    "D√©finissons une fonction pour charger les donn√©es depuis le fichier CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PASSENGERS</th>\n",
       "      <th>FREIGHT</th>\n",
       "      <th>MAIL</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>UNIQUE_CARRIER</th>\n",
       "      <th>AIRLINE_ID</th>\n",
       "      <th>UNIQUE_CARRIER_NAME</th>\n",
       "      <th>REGION</th>\n",
       "      <th>CARRIER</th>\n",
       "      <th>CARRIER_NAME</th>\n",
       "      <th>...</th>\n",
       "      <th>DEST</th>\n",
       "      <th>DEST_CITY_NAME</th>\n",
       "      <th>DEST_COUNTRY</th>\n",
       "      <th>DEST_COUNTRY_NAME</th>\n",
       "      <th>DEST_WAC</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>QUARTER</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DISTANCE_GROUP</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>AMQ</td>\n",
       "      <td>20201</td>\n",
       "      <td>Ameristar Air Cargo</td>\n",
       "      <td>I</td>\n",
       "      <td>AMQ</td>\n",
       "      <td>Ameristar Air Cargo</td>\n",
       "      <td>...</td>\n",
       "      <td>YQG</td>\n",
       "      <td>Windsor, Canada</td>\n",
       "      <td>CA</td>\n",
       "      <td>Canada</td>\n",
       "      <td>936</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>AMQ</td>\n",
       "      <td>20201</td>\n",
       "      <td>Ameristar Air Cargo</td>\n",
       "      <td>I</td>\n",
       "      <td>AMQ</td>\n",
       "      <td>Ameristar Air Cargo</td>\n",
       "      <td>...</td>\n",
       "      <td>YIP</td>\n",
       "      <td>Detroit, MI</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>43</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>AMQ</td>\n",
       "      <td>20201</td>\n",
       "      <td>Ameristar Air Cargo</td>\n",
       "      <td>I</td>\n",
       "      <td>AMQ</td>\n",
       "      <td>Ameristar Air Cargo</td>\n",
       "      <td>...</td>\n",
       "      <td>YIP</td>\n",
       "      <td>Detroit, MI</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>43</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>AMQ</td>\n",
       "      <td>20201</td>\n",
       "      <td>Ameristar Air Cargo</td>\n",
       "      <td>I</td>\n",
       "      <td>AMQ</td>\n",
       "      <td>Ameristar Air Cargo</td>\n",
       "      <td>...</td>\n",
       "      <td>YIP</td>\n",
       "      <td>Detroit, MI</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>43</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>AMQ</td>\n",
       "      <td>20201</td>\n",
       "      <td>Ameristar Air Cargo</td>\n",
       "      <td>I</td>\n",
       "      <td>AMQ</td>\n",
       "      <td>Ameristar Air Cargo</td>\n",
       "      <td>...</td>\n",
       "      <td>YIP</td>\n",
       "      <td>Detroit, MI</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>43</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PASSENGERS  FREIGHT  MAIL  DISTANCE UNIQUE_CARRIER  AIRLINE_ID  \\\n",
       "0         0.0      0.0   0.0      29.0            AMQ       20201   \n",
       "1         0.0      0.0   0.0      29.0            AMQ       20201   \n",
       "2         0.0      0.0   0.0      29.0            AMQ       20201   \n",
       "3         0.0      0.0   0.0      29.0            AMQ       20201   \n",
       "4         0.0      0.0   0.0      29.0            AMQ       20201   \n",
       "\n",
       "   UNIQUE_CARRIER_NAME REGION CARRIER         CARRIER_NAME  ...  DEST  \\\n",
       "0  Ameristar Air Cargo      I     AMQ  Ameristar Air Cargo  ...   YQG   \n",
       "1  Ameristar Air Cargo      I     AMQ  Ameristar Air Cargo  ...   YIP   \n",
       "2  Ameristar Air Cargo      I     AMQ  Ameristar Air Cargo  ...   YIP   \n",
       "3  Ameristar Air Cargo      I     AMQ  Ameristar Air Cargo  ...   YIP   \n",
       "4  Ameristar Air Cargo      I     AMQ  Ameristar Air Cargo  ...   YIP   \n",
       "\n",
       "    DEST_CITY_NAME  DEST_COUNTRY  DEST_COUNTRY_NAME  DEST_WAC  YEAR QUARTER  \\\n",
       "0  Windsor, Canada            CA             Canada       936  2010       2   \n",
       "1      Detroit, MI            US      United States        43  2010       1   \n",
       "2      Detroit, MI            US      United States        43  2010       2   \n",
       "3      Detroit, MI            US      United States        43  2010       3   \n",
       "4      Detroit, MI            US      United States        43  2010       3   \n",
       "\n",
       "  MONTH DISTANCE_GROUP  CLASS  \n",
       "0     6              1      P  \n",
       "1     3              1      P  \n",
       "2     6              1      P  \n",
       "3     8              1      P  \n",
       "4     9              1      P  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"C:/Users/Asus_M/Desktop/data.csv\"\n",
    "\n",
    "def load_data(data_path):\n",
    "    data = pd.read_csv(data_path, index_col=0)\n",
    "    return data\n",
    "\n",
    "data = load_data(data_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pr√©paration des Donn√©es\n",
    "Pr√©parons les donn√©es en nettoyant et en ajustant les types de donn√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54942, 26)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_data(data):\n",
    "    data.columns = data.columns.str.replace(' ', '', regex=False)\n",
    "    colonnes_avec_ID = [col for col in data.columns if 'ID' in col]\n",
    "    data.drop(columns=colonnes_avec_ID, axis=1, inplace=True)\n",
    "    \n",
    "    # Conversion des colonnes cat√©gorielles en objets\n",
    "    cat_columns = ['CARRIER_GROUP', 'CARRIER_GROUP_NEW', 'ORIGIN_WAC', 'DEST_WAC', 'YEAR', 'QUARTER', 'MONTH', 'DISTANCE_GROUP']\n",
    "    data[cat_columns] = data[cat_columns].astype(object)\n",
    "    \n",
    "    # Suppression des lignes avec PASSENGERS, FREIGHT, et MAIL tous √©gaux √† 0\n",
    "    lignes_zero_valeurs = data[(data['PASSENGERS'] == 0) & (data['FREIGHT'] == 0) & (data['MAIL'] == 0)].index\n",
    "    data.drop(lignes_zero_valeurs, inplace=True)\n",
    "    \n",
    "    # Suppression des valeurs manquantes\n",
    "    data.dropna(inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "prepared_data = prepare_data(data)\n",
    "prepared_data.head()\n",
    "prepared_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation des Donn√©es\n",
    "Transformons les donn√©es en encodant les variables cat√©gorielles et en appliquant une transformation logarithmique aux donn√©es num√©riques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Log_PASSENGERS', 'Log_FREIGHT', 'Log_MAIL', 'Log_DISTANCE',\n",
       "       'UNIQUE_CARRIER', 'UNIQUE_CARRIER_NAME', 'REGION', 'CARRIER',\n",
       "       'CARRIER_NAME', 'CARRIER_GROUP', 'CARRIER_GROUP_NEW', 'ORIGIN',\n",
       "       'ORIGIN_CITY_NAME', 'ORIGIN_COUNTRY', 'ORIGIN_COUNTRY_NAME',\n",
       "       'ORIGIN_WAC', 'DEST', 'DEST_CITY_NAME', 'DEST_COUNTRY',\n",
       "       'DEST_COUNTRY_NAME', 'DEST_WAC', 'YEAR', 'QUARTER', 'MONTH',\n",
       "       'DISTANCE_GROUP', 'CLASS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_data(prepared_data):\n",
    "    label_encoder = LabelEncoder()\n",
    "    cat_data = prepared_data.select_dtypes(include='object')\n",
    "    num_data = prepared_data.select_dtypes(exclude='object')\n",
    "    \n",
    "    # Transformation logarithmique\n",
    "    num_data['Log_PASSENGERS'] = np.log1p(num_data['PASSENGERS'])\n",
    "    num_data['Log_FREIGHT'] = np.log1p(num_data['FREIGHT'])\n",
    "    num_data['Log_MAIL'] = np.log1p(num_data['MAIL'])\n",
    "    num_data['Log_DISTANCE'] = np.log1p(num_data['DISTANCE'])\n",
    "    num_data.drop(columns=['PASSENGERS', 'FREIGHT', 'MAIL', 'DISTANCE'], inplace=True)\n",
    "    \n",
    "    # Encodage des variables cat√©gorielles\n",
    "    for column in cat_data.columns:\n",
    "        cat_data[column] = label_encoder.fit_transform(cat_data[column])\n",
    "    \n",
    "    data = pd.concat([num_data, cat_data], axis=1)\n",
    "    return data\n",
    "\n",
    "transformed_data = transform_data(prepared_data)\n",
    "transformed_data.head()\n",
    "transformed_data.shape\n",
    "transformed_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Division des Donn√©es\n",
    "Divisons les donn√©es en ensembles d'entra√Ænement et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43953, 23)\n",
      "(43953, 3)\n",
      "(10989, 23)\n",
      "(10989, 3)\n"
     ]
    }
   ],
   "source": [
    "def split_data(transformed_data):\n",
    "    X = transformed_data.drop(columns=[\"Log_PASSENGERS\", \"Log_FREIGHT\", \"Log_MAIL\"])\n",
    "    y = transformed_data[[\"Log_PASSENGERS\", \"Log_FREIGHT\", \"Log_MAIL\"]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(transformed_data)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S√©lection des Caract√©ristiques\n",
    "Utilisons la m√©thode SequentialFeatureSelector pour s√©lectionner les meilleures caract√©ristiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  23 | elapsed:  2.7min remaining:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  23 | elapsed:  4.1min finished\n",
      "\n",
      "[2024-08-07 11:46:37] Features: 22/1 -- score: -0.749452776786056[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  22 | elapsed:  1.8min remaining:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  22 | elapsed:  3.2min finished\n",
      "\n",
      "[2024-08-07 11:49:49] Features: 21/1 -- score: -0.7465249047195583[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  21 | elapsed:  1.8min remaining:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:  3.0min finished\n",
      "\n",
      "[2024-08-07 11:52:47] Features: 20/1 -- score: -0.7443903165484197[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  20 | elapsed:  1.7min remaining:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  2.7min finished\n",
      "\n",
      "[2024-08-07 11:55:28] Features: 19/1 -- score: -0.742873737953648[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  19 | elapsed:  1.6min remaining:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  19 | elapsed:  2.4min remaining:   27.2s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:  2.4min finished\n",
      "\n",
      "[2024-08-07 11:57:55] Features: 18/1 -- score: -0.7423498984093619[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  18 | elapsed:  1.4min remaining:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  18 | elapsed:  2.1min remaining:   25.5s\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:  2.2min finished\n",
      "\n",
      "[2024-08-07 12:00:04] Features: 17/1 -- score: -0.7425118246052463[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  17 | elapsed:  1.3min remaining:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  17 | elapsed:  1.5min remaining:   37.3s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:  1.9min finished\n",
      "\n",
      "[2024-08-07 12:02:01] Features: 16/1 -- score: -0.7410849813637478[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  16 | elapsed:  1.2min remaining:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  16 | elapsed:  1.4min remaining:   39.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:  1.8min finished\n",
      "\n",
      "[2024-08-07 12:03:47] Features: 15/1 -- score: -0.742824729939807[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:  1.3min remaining:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.6min finished\n",
      "\n",
      "[2024-08-07 12:05:21] Features: 14/1 -- score: -0.7415322347980119[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  14 | elapsed:  1.2min remaining:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:  1.4min finished\n",
      "\n",
      "[2024-08-07 12:06:46] Features: 13/1 -- score: -0.7399686105927322[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  13 | elapsed:  1.2min remaining:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  13 | elapsed:  1.2min remaining:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:  1.3min finished\n",
      "\n",
      "[2024-08-07 12:08:04] Features: 12/1 -- score: -0.7410291688958598[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  12 | elapsed:  1.1min remaining:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  12 | elapsed:  1.1min remaining:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  1.1min finished\n",
      "\n",
      "[2024-08-07 12:09:09] Features: 11/1 -- score: -0.7433936826897308[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  11 | elapsed:   56.2s remaining:   46.8s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:   58.1s finished\n",
      "\n",
      "[2024-08-07 12:10:07] Features: 10/1 -- score: -0.7434790362091358[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:   49.6s remaining:   49.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   50.8s finished\n",
      "\n",
      "[2024-08-07 12:10:58] Features: 9/1 -- score: -0.7498389223943712[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:   44.2s remaining:   22.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   44.5s finished\n",
      "\n",
      "[2024-08-07 12:11:43] Features: 8/1 -- score: -0.7537882071291818[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   8 | elapsed:   33.5s remaining:   20.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   34.7s finished\n",
      "\n",
      "[2024-08-07 12:12:18] Features: 7/1 -- score: -0.7617312812372604[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   7 | elapsed:   26.4s remaining:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:   27.0s finished\n",
      "\n",
      "[2024-08-07 12:12:45] Features: 6/1 -- score: -0.7994019659744437[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:   18.0s remaining:   18.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:   19.4s finished\n",
      "\n",
      "[2024-08-07 12:13:04] Features: 5/1 -- score: -0.8325361968516242[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    8.8s remaining:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    9.4s finished\n",
      "\n",
      "[2024-08-07 12:13:14] Features: 4/1 -- score: -0.953025831823577[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:    6.2s remaining:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    6.6s finished\n",
      "\n",
      "[2024-08-07 12:13:21] Features: 3/1 -- score: -1.2123174721235088[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    3.2s finished\n",
      "\n",
      "[2024-08-07 12:13:24] Features: 2/1 -- score: -1.677078070230581[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices des caract√©ristiques s√©lectionn√©es : [0, 3, 5, 7, 8, 9, 12, 13, 14, 18, 20, 21, 22]\n",
      "Noms des caract√©ristiques s√©lectionn√©es : ['Log_DISTANCE', 'REGION', 'CARRIER_NAME', 'CARRIER_GROUP_NEW', 'ORIGIN', 'ORIGIN_CITY_NAME', 'ORIGIN_WAC', 'DEST', 'DEST_CITY_NAME', 'YEAR', 'MONTH', 'DISTANCE_GROUP', 'CLASS']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    1.3s finished\n",
      "\n",
      "[2024-08-07 12:13:25] Features: 1/1 -- score: -3.8728223161012885"
     ]
    }
   ],
   "source": [
    "def select_features(X_train, y_train, k_features='best', n_jobs=-1, cv=3, scoring='neg_mean_squared_error', verbose=2):\n",
    "    etr = ExtraTreesRegressor(n_jobs=n_jobs,random_state=42)\n",
    "    sfs = SFS(\n",
    "        etr,\n",
    "        k_features=k_features,\n",
    "        forward=False,\n",
    "        floating=False,\n",
    "        verbose=verbose,\n",
    "        scoring=scoring,\n",
    "        cv=cv,\n",
    "        n_jobs=n_jobs\n",
    "    )\n",
    "    \n",
    "    # Perform feature selection using joblib for parallel processing\n",
    "    with parallel_backend('threading', n_jobs=n_jobs):\n",
    "        sfs = sfs.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the selected feature indices\n",
    "    selected_feature_indices = sfs.k_feature_idx_\n",
    "    \n",
    "    if isinstance(X_train, pd.DataFrame):\n",
    "        feature_names = X_train.columns[list(selected_feature_indices)]\n",
    "        return list(selected_feature_indices), feature_names.tolist()\n",
    "    else:\n",
    "        return list(selected_feature_indices)\n",
    "\n",
    "selected_indices, selected_feature_names = select_features(X_train, y_train)\n",
    "print(\"Indices des caract√©ristiques s√©lectionn√©es :\", selected_indices)\n",
    "print(\"Noms des caract√©ristiques s√©lectionn√©es :\", selected_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrage des Caract√©ristiques\n",
    "Filtrons les donn√©es d'entra√Ænement et de test pour ne conserver que les caract√©ristiques s√©lectionn√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train avec les caract√©ristiques s√©lectionn√©es : (43953, 13)\n",
      "X_test avec les caract√©ristiques s√©lectionn√©es : (10989, 13)\n",
      "y_train : (43953, 3)\n",
      "y_test : (10989, 3)\n"
     ]
    }
   ],
   "source": [
    "def filter_features(X_train, X_test, selected_indices):\n",
    "    if isinstance(X_train, pd.DataFrame):\n",
    "        return X_train.iloc[:, selected_indices], X_test.iloc[:, selected_indices]\n",
    "    else:\n",
    "        return X_train[:, selected_indices], X_test[:, selected_indices]\n",
    "\n",
    "X_train_selected, X_test_selected = filter_features(X_train, X_test, selected_indices)\n",
    "print(\"X_train avec les caract√©ristiques s√©lectionn√©es :\", X_train_selected.shape)\n",
    "print(\"X_test avec les caract√©ristiques s√©lectionn√©es :\", X_test_selected.shape)\n",
    "print(\"y_train :\", y_train.shape)\n",
    "print(\"y_test :\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enregistrement des features dans un fichier TXT :\n",
    "Apr√©s l'etape de selection ,nous enregistrons les donn√©es avec les features selectionn√©es dans un fichier txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les noms des colonnes ont √©t√© enregistr√©s dans features.txt.\n"
     ]
    }
   ],
   "source": [
    "columns = X_train_selected.columns.tolist()\n",
    "\n",
    "with open('features.txt', 'w') as file:\n",
    "    for column in columns:\n",
    "        file.write(f\"{column}\\n\")\n",
    "\n",
    "print(\"Les noms des colonnes ont √©t√© enregistr√©s dans features.txt.\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entra√Ænement et Enregistrement des Mod√®les\n",
    "Entra√Ænons plusieurs mod√®les et enregistrons-les avec MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/07 12:13:28 INFO mlflow.tracking.fluent: Experiment with name 'experience1' does not exist. Creating a new experiment.\n",
      "2024/08/07 12:13:36 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2024/08/07 12:13:36 INFO mlflow.tracking._tracking_service.client: üèÉ View run LinearRegression at: http://localhost:5000/#/experiments/995444263188306398/runs/9b436f8930a743d3adfc4541593898b3.\n",
      "2024/08/07 12:13:36 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://localhost:5000/#/experiments/995444263188306398.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mod√®le: LinearRegression, R2: 0.1832, RMSE: 2.9935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/07 12:14:06 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2024/08/07 12:14:07 INFO mlflow.tracking._tracking_service.client: üèÉ View run RandomForestRegressor at: http://localhost:5000/#/experiments/995444263188306398/runs/2ebdf0293b6e4e99a0ab0d715ffbf9b5.\n",
      "2024/08/07 12:14:07 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://localhost:5000/#/experiments/995444263188306398.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mod√®le: RandomForestRegressor, R2: 0.9263, RMSE: 0.8188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/07 12:14:11 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2024/08/07 12:14:11 INFO mlflow.tracking._tracking_service.client: üèÉ View run KNeighborsRegressor at: http://localhost:5000/#/experiments/995444263188306398/runs/ec5dac052297454b8e9e599f66e7e199.\n",
      "2024/08/07 12:14:11 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://localhost:5000/#/experiments/995444263188306398.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mod√®le: KNeighborsRegressor, R2: 0.8440, RMSE: 1.2745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/07 12:14:35 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2024/08/07 12:14:35 INFO mlflow.tracking._tracking_service.client: üèÉ View run ExtraTreesRegressor at: http://localhost:5000/#/experiments/995444263188306398/runs/7804aba9c89a4213ba39fa23753ea05f.\n",
      "2024/08/07 12:14:35 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://localhost:5000/#/experiments/995444263188306398.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mod√®le: ExtraTreesRegressor, R2: 0.9262, RMSE: 0.8243\n",
      "\n",
      "Le meilleur mod√®le est 'RandomForestRegressor' avec R2 = 0.9263 et RMSE = 0.8188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/07 12:14:44 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "Successfully registered model 'Best_Model'.\n",
      "2024/08/07 12:14:44 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Best_Model, version 1\n",
      "Created version '1' of model 'Best_Model'.\n",
      "2024/08/07 12:14:44 INFO mlflow.tracking._tracking_service.client: üèÉ View run Best_Model_Production at: http://localhost:5000/#/experiments/995444263188306398/runs/c54223f5e2cd4eeaafa34bdd9b77f31a.\n",
      "2024/08/07 12:14:44 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://localhost:5000/#/experiments/995444263188306398.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le mod√®le 'RandomForestRegressor' a √©t√© enregistr√© et mis en production.\n"
     ]
    }
   ],
   "source": [
    "# D√©finir l'URI de suivi et l'exp√©rience MLflow\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment('experience1')\n",
    "\n",
    "def train_and_log_model(model_name, model, X_train_selected, y_train, X_test_selected, y_test):\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Entra√Æner le mod√®le\n",
    "        model.fit(X_train_selected, y_train)\n",
    "        \n",
    "        # Pr√©dictions\n",
    "        predictions = model.predict(X_test_selected)\n",
    "        \n",
    "        # Calculer l'erreur quadratique moyenne et R2\n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        rmse = np.sqrt(mse)  # Calculer RMSE\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "        \n",
    "        # Loguer les param√®tres et les r√©sultats\n",
    "        mlflow.log_params(model.get_params())\n",
    "        mlflow.log_metric(\"mean_squared_error\", mse)\n",
    "        mlflow.log_metric(\"root_mean_squared_error\", rmse)\n",
    "        mlflow.log_metric(\"R2\", r2)\n",
    "        \n",
    "        # Loguer le mod√®le\n",
    "        mlflow.sklearn.log_model(model, model_name)\n",
    "        \n",
    "        return r2, rmse\n",
    "\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'RandomForestRegressor': RandomForestRegressor(),\n",
    "    'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "    'ExtraTreesRegressor': ExtraTreesRegressor()\n",
    "}\n",
    "\n",
    "best_model_name = None\n",
    "best_r2 = -np.inf\n",
    "best_rmse = np.inf\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    r2, rmse = train_and_log_model(model_name, model, X_train_selected, y_train, X_test_selected, y_test)\n",
    "    print(f\"Mod√®le: {model_name}, R2: {r2:.4f}, RMSE: {rmse:.4f}\")\n",
    "    \n",
    "    # Mettre √† jour le meilleur mod√®le bas√© sur R2 et RMSE\n",
    "    if r2 > best_r2 and rmse < best_rmse:\n",
    "        best_r2 = r2\n",
    "        best_rmse = rmse\n",
    "        best_model_name = model_name\n",
    "\n",
    "if best_model_name:\n",
    "    print(f\"\\nLe meilleur mod√®le est '{best_model_name}' avec R2 = {best_r2:.4f} et RMSE = {best_rmse:.4f}\")\n",
    "\n",
    "    # Enregistrer le meilleur mod√®le\n",
    "    with mlflow.start_run(run_name=\"Best_Model_Production\") as best_run:\n",
    "        best_model = models[best_model_name]\n",
    "        mlflow.sklearn.log_model(best_model, \"best_model\")\n",
    "        mlflow.log_metric(\"R2\", best_r2)\n",
    "        mlflow.log_metric(\"root_mean_squared_error\", best_rmse)\n",
    "        \n",
    "        # Enregistrer le mod√®le dans le registre MLflow\n",
    "        model_uri = f\"runs:/{best_run.info.run_id}/best_model\"\n",
    "        mlflow.register_model(model_uri, \"Best_Model\")\n",
    "\n",
    "        # D√©placer le mod√®le vers le stage de production\n",
    "        client = MlflowClient()\n",
    "        latest_version = client.get_latest_versions(\"Best_Model\", stages=[\"None\"])[0].version\n",
    "        client.transition_model_version_stage(\n",
    "            name=\"Best_Model\",\n",
    "            version=latest_version,\n",
    "            stage=\"Production\"\n",
    "        )\n",
    "\n",
    "    print(f\"Le mod√®le '{best_model_name}' a √©t√© enregistr√© et mis en production.\")\n",
    "else:\n",
    "    print(\"Aucun mod√®le n'a √©t√© s√©lectionn√©.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation du Mod√®le\n",
    "V√©rifions que le mod√®le enregistr√© fonctionne correctement avant de le d√©ployer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model URI in production: models:/Best_Model/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:46<00:00,  9.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le nombre de passagers pr√©vu est : 50\n",
      "La quantit√© de Fret pr√©vue : 1\n",
      "La quantit√© de Courrier pr√©vue est : 1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Define MLflow tracking URI\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "def get_model_uri_from_stage(model_name, stage=\"Production\"):\n",
    "    client = MlflowClient()\n",
    "    # Get the latest version of the model in the specified stage\n",
    "    model_versions = client.get_latest_versions(model_name, stages=[stage])\n",
    "    if not model_versions:\n",
    "        raise ValueError(f\"No version of model '{model_name}' found in stage '{stage}'.\")\n",
    "    \n",
    "    # Get the model URI\n",
    "    latest_version = model_versions[0].version\n",
    "    model_uri = f\"models:/{model_name}/{latest_version}\"\n",
    "    return model_uri\n",
    "\n",
    "def convert_input_example_to_serving_input(input_example):\n",
    "    # Convert DataFrame to NumPy array\n",
    "    if isinstance(input_example, pd.DataFrame):\n",
    "        input_example = input_example.values\n",
    "    \n",
    "    # Return as a list of lists (2D array) which is often expected by models\n",
    "    return input_example.tolist()\n",
    "\n",
    "def validate_serving_input(model_uri, serving_payload):\n",
    "    # Load the model\n",
    "    model = mlflow.pyfunc.load_model(model_uri)\n",
    "    \n",
    "    # Make a prediction\n",
    "    prediction = model.predict(serving_payload)\n",
    "    \n",
    "    # Print the prediction\n",
    "    prediction_original = np.exp(prediction)\n",
    "    passengers = prediction_original[0][0]\n",
    "    freight = prediction_original[0][1]\n",
    "    mail = prediction_original[0][2]\n",
    "\n",
    "    print(f\"Le nombre de passagers pr√©vu est : {math.floor(passengers)}\")\n",
    "    print(f\"La quantit√© de Fret pr√©vue : {math.floor(freight)}\")\n",
    "    print(f\"La quantit√© de Courrier pr√©vue est : {math.floor(mail)}\")\n",
    "\n",
    "\n",
    "# Example input data\n",
    "INPUT_EXAMPLE = {\n",
    "    \"Log_DISTANCE\": 7.723120,\n",
    "    \"REGION\": 1,\n",
    "    \"CARRIER_NAME\": 7,\n",
    "    \"CARRIER_GROUP_NEW\": 2,\n",
    "    \"ORIGIN\": 326,\n",
    "    \"ORIGIN_WAC\": 48,\n",
    "    \"DEST\": 412,\n",
    "    \"DEST_CITY_NAME\": 351,\n",
    "    \"DEST_WAC\": 58,\n",
    "    \"YEAR\": 2,\n",
    "    \"MONTH\": 6,\n",
    "    \"DISTANCE_GROUP\": 4,\n",
    "    \"CLASS\": 0\n",
    "}\n",
    "\n",
    "\n",
    "# Convert input example to DataFrame\n",
    "input_df = pd.DataFrame([INPUT_EXAMPLE])\n",
    "\n",
    "# Obtain the model URI\n",
    "model_name = \"Best_Model\"  # Model name\n",
    "model_uri = get_model_uri_from_stage(model_name, stage=\"Production\")\n",
    "print(f\"Model URI in production: {model_uri}\")\n",
    "\n",
    "# Convert the input example to a serving input format\n",
    "serving_payload = convert_input_example_to_serving_input(input_df)\n",
    "\n",
    "# Validate the model with the example input\n",
    "validate_serving_input(model_uri, serving_payload)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-07 12:15:32.396282\n"
     ]
    }
   ],
   "source": [
    "end_time = datetime.datetime.now()\n",
    "\n",
    "print(end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 day, 23:26:40.867521\n"
     ]
    }
   ],
   "source": [
    "temps_total_pour_execution = start_time - end_time\n",
    "\n",
    "print(temps_total_pour_execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
